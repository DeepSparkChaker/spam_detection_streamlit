{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import re # regex library\n",
    "# Read the Data\n",
    "# Train, Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Training a Neural Network Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.8\n"
     ]
    }
   ],
   "source": [
    "!python --version "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Model config in json format\"\"\"\n",
    "cfg = {\n",
    "    \"data\": {\n",
    "        ##alldata\n",
    "        \"path\": \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/Deploy_Spam_Detection/data/spam_data.csv\"\n",
    "        # small sample:\n",
    "       # \"path\": \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/FraudDetection/X_train_transactions_train.csv\"\n",
    "    },\n",
    "    # \"data_test\": {\n",
    "    #   \"path\": \"../input/ventilator-pressure-prediction/test.csv\"\n",
    "    # },\n",
    "    # \"data_submission\": {\n",
    "    #   \"path\": \"../input/ventilator-pressure-prediction/test.csv\"\n",
    "    # },\n",
    "    \"train\": {\n",
    "        'fit_params': {'early_stopping_rounds': 100, 'verbose': 55000},\n",
    "        'n_fold': 5,\n",
    "        'seeds': [2021],\n",
    "        'target_col': \"Fraud\",\n",
    "        'debug': False\n",
    "\n",
    "    },\n",
    "    \"model\": {'n_estimators': 11932, \n",
    "                    'max_depth': 16, \n",
    "                    'learning_rate': 0.005352340588475586,\n",
    "                    'lambda_l1': 1.4243404105489683e-06,\n",
    "                    'lambda_l2': 0.04777178032735788,\n",
    "                    'num_leaves': 141, \n",
    "                    'feature_fraction': 0.6657626611307914, \n",
    "                    'bagging_fraction': 0.9115997498937961,\n",
    "                    'bagging_freq': 1,\n",
    "                    'min_child_samples': 51,\n",
    "                     \"objective\": \"binary\",\n",
    "                     #\"metric\": \"binary_logloss\",\n",
    "                     \"verbosity\": -1,\n",
    "                     \"boosting_type\": \"gbdt\",\n",
    "                     #\"random_state\": 228,\n",
    "                     \"metric\": \"auc\",\n",
    "                     #\"device\": \"gpu\",\n",
    "                     'tree_method': \"gpu_hist\"\n",
    "                    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    \"\"\"save log\"\"\"\n",
    "    def __init__(self, path):\n",
    "        self.general_logger = logging.getLogger(path)\n",
    "        stream_handler = logging.StreamHandler()\n",
    "        file_general_handler = logging.FileHandler(os.path.join(path, 'Experiment.log'))\n",
    "        if len(self.general_logger.handlers) == 0:\n",
    "            self.general_logger.addHandler(stream_handler)\n",
    "            self.general_logger.addHandler(file_general_handler)\n",
    "            self.general_logger.setLevel(logging.INFO)\n",
    "\n",
    "    def info(self, message):\n",
    "        # display time\n",
    "        self.general_logger.info('[{}] - {}'.format(self.now_string(), message))\n",
    "\n",
    "    @staticmethod\n",
    "    def now_string():\n",
    "        return str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    \n",
    "class Util:\n",
    "    \"\"\"save & load\"\"\"\n",
    "    @classmethod\n",
    "    def dump(cls, value, path):\n",
    "        joblib.dump(value, path, compress=True)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        return joblib.load(path)\n",
    "        \n",
    "class HorizontalDisplay:\n",
    "    \"\"\"display dataframe\"\"\"\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        template = '<div style=\"float: left; padding: 10px;\">{0}</div>'\n",
    "        return \"\\n\".join(template.format(arg._repr_html_())\n",
    "                         for arg in self.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Config class\"\"\"\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "class Config:\n",
    "    name_v1 = \"lgb baseline\"\n",
    "    \"\"\"Config class which contains data, train and model hyperparameters\"\"\"\n",
    "    def __init__(self, data, train, model):\n",
    "        self.data = data\n",
    "        self.train = train\n",
    "        self.model = model\n",
    "    @classmethod\n",
    "    def from_json(cls, cfg):\n",
    "        \"\"\"Creates config from json\"\"\"\n",
    "        params = json.loads(json.dumps(cfg), object_hook=lambda d: SimpleNamespace(**d))\n",
    "        return cls(params.data, params.train, params.model)\n",
    "\n",
    "class HelperObject(object):\n",
    "    \"\"\"Helper class to convert json into Python object\"\"\"\n",
    "    def __init__(self, dict_):\n",
    "        self.__dict__.update(dict_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "  Category                                            Message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "shape of data (5572, 2)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Data Loader\"\"\"\n",
    "class DataLoader:\n",
    "    \"\"\"Data Loader class\"\"\"\n",
    "    @staticmethod\n",
    "    def load_data(data_config):\n",
    "        \"\"\"Loads dataset from path\"\"\"\n",
    "        return pd.read_csv(data_config.path)\n",
    "    \n",
    "%time\n",
    "if __name__ == \"__main__\":\n",
    "    train = DataLoader().load_data(Config.from_json(cfg).data)\n",
    "    print(train.head())\n",
    "    print('shape of data {}'.format(train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\rzouga\\\\Desktop\\\\ALLINHERE\\\\ALLINHERE\\\\Deploy_Spam_Detection\\\\notebook'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "current_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloder=DataLoader()\n",
    "data = dataloder.load_data(Config.from_json(cfg).data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('./data/spam_data.csv')\n",
    "# Text Preprocessing\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text) # Effectively removes HTML markup tags\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    return text\n",
    "# Define X and y \n",
    "X = data['Message'].apply(preprocessor)\n",
    "y = data['Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'squeeeeeze this is christmas hug if u lik my frndshp den hug me back if u get 3 u r cute 6 u r luvd 9 u r so lucky none people hate u :) ;)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99      1448\n",
      "        spam       0.96      0.92      0.94       224\n",
      "\n",
      "    accuracy                           0.98      1672\n",
      "   macro avg       0.97      0.96      0.96      1672\n",
      "weighted avg       0.98      0.98      0.98      1672\n",
      "\n",
      "Accuracy: 98.38516746411483 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/Deploy_Spam_Detection/models/spam_classifier.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, \n",
    "                        max_features=700, \n",
    "                        ngram_range=(1,1))\n",
    "neural_net_pipeline = Pipeline([('vectorizer', tfidf), \n",
    "                                ('nn', MLPClassifier(hidden_layer_sizes=(700, 700)))])\n",
    "neural_net_pipeline.fit(X_train, y_train)\n",
    "# Testing the Pipeline\n",
    "y_pred = neural_net_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Accuracy: {} %'.format(100 * accuracy_score(y_test, y_pred)))\n",
    "# Saving the Pipeline\n",
    "dump(neural_net_pipeline, 'C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/Deploy_Spam_Detection/models/spam_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21986705334812853"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model data\n",
    "import joblib\n",
    "#f = \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/FraudDetection/DeployPipeComplet/models/model_test.joblib\"\n",
    "f = \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/Deploy_Spam_Detection/models/spam_classifier.joblib\"\n",
    "model = joblib.load(f)\n",
    "item={}\n",
    "item={\"message\":'squeeeeeze this is christmas hug if u lik my frndshp den hug me back if u get 3 u r cute 6 u r luvd 9 u r so lucky none people hate u :) ;)'\n",
    "     }\n",
    "df = pd.json_normalize(item)\n",
    "df2 =pd.DataFrame([item])\n",
    "prediction = model.predict_proba(df2)\n",
    "prediction[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>squeeeeeze this is christmas hug if u lik my f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message\n",
       "0  squeeeeeze this is christmas hug if u lik my f..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(df)\n",
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'proba': 0.21986705334812853, 'result': 'ham'}\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_proba(df)\n",
    "prediction_final=model.predict(df)\n",
    "h={\"proba\": prediction[0][1], \"result\" :prediction_final[0]}\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [7612]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:4000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:50080 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50081 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50081 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50692 - \"POST /predict-fraud HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:50695 - \"POST /docs HTTP/1.1\" 405 Method Not Allowed\n",
      "INFO:     127.0.0.1:50703 - \"GET /predict_fraud_predict_spam_post HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:50709 - \"POST /basic_predict_basic_predict_spam_post HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:50711 - \"POST /basic_predict_basic_predict_spam_post HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:50715 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50715 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50717 - \"POST /predict-spam HTTP/1.1\" 422 Unprocessable Entity\n",
      "INFO:     127.0.0.1:50718 - \"POST /predict-spam HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50719 - \"POST /basic_predict_basic_predict_spam_post HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:50721 - \"POST /predict-spam HTTP/1.1\" 422 Unprocessable Entity\n",
      "INFO:     127.0.0.1:50722 - \"POST /predict-spam HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51131 - \"GET /ping HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52431 - \"POST /predict-spam HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [7612]\n"
     ]
    }
   ],
   "source": [
    "# First, we will need to import the library and initialize the main application object:\n",
    "import joblib\n",
    "import uvicorn\n",
    "from fastapi import FastAPI,Request, File, UploadFile, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import nest_asyncio\n",
    "from typing import Any, Dict,List\n",
    "        \n",
    "## API INSTANTIATION\n",
    "## ----------------------------------------------------------------\n",
    "       \n",
    "app = FastAPI(\n",
    "    title=\"Spam Detection API\",\n",
    "    description=\"A simple API that use Ml model to predict Spam \",\n",
    "    version=\"0.1\",\n",
    ")\n",
    "# Creating the data model for data validation\n",
    "class ClientData(BaseModel):\n",
    "    message: str\n",
    "#load model data\n",
    "f = \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/Deploy_Spam_Detection/models/spam_classifier.joblib\"\n",
    "#f = \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/FraudDetection/DeployPipeComplet/models/pipeline_model_lgbm_final.joblib\"\n",
    "model = joblib.load(f)\n",
    "    \n",
    "## API ENDPOINTS\n",
    "## ----------------------------------------------------------------\n",
    "## API ENDPOINTS\n",
    "## ----------------------------------------------------------------\n",
    "\n",
    "# Preprocess Heleper \n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text) # Effectively removes HTML markup tags\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    return text\n",
    "# Predict Function \n",
    "def classify_message(model, message):\n",
    "\n",
    "\tmessage = preprocessor(message)\n",
    "\tlabel = model.predict([message])[0]\n",
    "\tspam_prob = model.predict_proba([message])\n",
    "\n",
    "\treturn {'label': label, 'spam_probability': spam_prob[0][1]}\n",
    "\n",
    "##################\n",
    "@app.get('/')\n",
    "def index():\n",
    "  '''\n",
    "  This is a first docstring.\n",
    "  '''\n",
    "  return {'message': 'This is a Fraud  Classification API!'}\n",
    "\n",
    "# Tester\n",
    "@app.get('/ping')\n",
    "def ping():\n",
    "  '''\n",
    "  This is a first docstring.\n",
    "  '''\n",
    "  return ('pong', 200)\n",
    "# Defining the prediction endpoint without data validation\n",
    "@app.post('/basic_predict_spam')\n",
    "async def basic_predict(request: Request):\n",
    "    '''\n",
    "    This is a first docstring.\n",
    "    '''\n",
    "    # Getting the JSON from the body of the request\n",
    "    messsage = await request.json()\n",
    "    return classify_message(model, message)\n",
    "\n",
    "# We now define the function that will be executed for each URL request and return the value:\n",
    "@app.post(\"/predict-spam\")\n",
    "async  def predict_fraud(item :ClientData):\n",
    "    \"\"\"\n",
    "    A simple function that receive a client data and predict Spam.\n",
    "    :param client_data:\n",
    "    :return: prediction, probabilities\n",
    "    \"\"\"\n",
    "    # perform prediction\n",
    "    #df =pd.DataFrame([item])\n",
    "    #h=item.dict()\n",
    "    return classify_message(model, str(item))\n",
    "    \n",
    "    # Create the POST endpoint with path '/predict'\n",
    "@app.post(\"/predict_csv\")\n",
    "async def create_upload_file(file: UploadFile = File(...)):\n",
    "    # Handle the file only if it is a CSV\n",
    "    if file.filename.endswith(\".csv\"):\n",
    "        # Create a temporary file with the same name as the uploaded \n",
    "        # CSV file to load the data into a pandas Dataframe\n",
    "        with open(file.filename, \"wb\")as f:\n",
    "            f.write(file.file.read())\n",
    "        data = pd.read_csv(file.filename)\n",
    "        os.remove(file.filename)\n",
    "        # Return a JSON object containing the model predictions\n",
    "        return {\n",
    "            \"predictions\": model.predict(data)\n",
    "        }    \n",
    "    else:\n",
    "        # Raise a HTTP 400 Exception, indicating Bad Request \n",
    "        # (you can learn more about HTTP response status codes here)\n",
    "        raise HTTPException(status_code=400, detail=\"Invalid file format. Only CSV Files accepted.\")\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=4000)\n",
    "# uvicorn app:app --reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "fastapi             0.65.0\n",
       "joblib              1.0.1\n",
       "nest_asyncio        NA\n",
       "numpy               1.19.5\n",
       "pandas              1.2.4\n",
       "pydantic            NA\n",
       "session_info        1.0.0\n",
       "sklearn             0.24.1\n",
       "starlette           0.14.2\n",
       "uvicorn             0.15.0\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "Cython              0.29.23\n",
       "anyio               NA\n",
       "asgiref             3.4.1\n",
       "attr                20.3.0\n",
       "babel               2.9.0\n",
       "backcall            0.2.0\n",
       "bottleneck          1.3.2\n",
       "brotli              NA\n",
       "certifi             2020.12.05\n",
       "chardet             4.0.0\n",
       "click               7.1.2\n",
       "colorama            0.4.3\n",
       "cython              0.29.23\n",
       "cython_runtime      NA\n",
       "dateutil            2.8.1\n",
       "decorator           5.0.6\n",
       "google              NA\n",
       "h11                 0.12.0\n",
       "idna                2.10\n",
       "ipykernel           5.3.4\n",
       "ipython_genutils    0.2.0\n",
       "jedi                0.17.2\n",
       "jinja2              2.11.3\n",
       "json5               NA\n",
       "jsonschema          3.2.0\n",
       "jupyter_server      1.4.1\n",
       "jupyterlab_server   2.4.0\n",
       "markupsafe          2.0.1\n",
       "mpl_toolkits        NA\n",
       "multipart           0.0.5\n",
       "nbclassic           NA\n",
       "nbformat            5.1.3\n",
       "nt                  NA\n",
       "ntsecuritycon       NA\n",
       "packaging           21.3\n",
       "parso               0.7.0\n",
       "pickleshare         0.7.5\n",
       "pkg_resources       NA\n",
       "prometheus_client   NA\n",
       "prompt_toolkit      3.0.17\n",
       "psutil              5.8.0\n",
       "pvectorc            NA\n",
       "pygments            2.8.1\n",
       "pyrsistent          NA\n",
       "pythoncom           NA\n",
       "pytz                2021.1\n",
       "pywintypes          NA\n",
       "requests            2.25.1\n",
       "scipy               1.6.2\n",
       "send2trash          NA\n",
       "six                 1.15.0\n",
       "sniffio             1.2.0\n",
       "socks               1.7.1\n",
       "sphinxcontrib       NA\n",
       "storemagic          NA\n",
       "tornado             6.1\n",
       "traitlets           5.0.5\n",
       "typing_extensions   NA\n",
       "ujson               4.0.2\n",
       "urllib3             1.26.4\n",
       "wcwidth             0.2.5\n",
       "win32api            NA\n",
       "win32com            NA\n",
       "win32security       NA\n",
       "yaml                5.4.1\n",
       "zmq                 20.0.0\n",
       "zope                NA\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             7.22.0\n",
       "jupyter_client      6.1.12\n",
       "jupyter_core        4.7.1\n",
       "jupyterlab          3.0.14\n",
       "notebook            6.3.0\n",
       "-----\n",
       "Python 3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]\n",
       "Windows-7-6.1.7601-SP1\n",
       "-----\n",
       "Session information updated at 2022-01-26 13:11\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pipreqs\n",
      "  Downloading pipreqs-0.4.11-py2.py3-none-any.whl (32 kB)\n",
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting yarg\n",
      "  Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\rzouga\\anaconda3\\lib\\site-packages (from yarg->pipreqs) (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\rzouga\\anaconda3\\lib\\site-packages (from requests->yarg->pipreqs) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\rzouga\\anaconda3\\lib\\site-packages (from requests->yarg->pipreqs) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rzouga\\anaconda3\\lib\\site-packages (from requests->yarg->pipreqs) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rzouga\\anaconda3\\lib\\site-packages (from requests->yarg->pipreqs) (1.26.4)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=39ea6745695769f61d1e1374ccd3453a35565ea3935cc5143e71befa5147347f\n",
      "  Stored in directory: c:\\users\\rzouga\\appdata\\local\\pip\\cache\\wheels\\56\\ea\\58\\ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "Successfully built docopt\n",
      "Installing collected packages: yarg, docopt, pipreqs\n",
      "Successfully installed docopt-0.6.2 pipreqs-0.4.11 yarg-0.1.9\n"
     ]
    }
   ],
   "source": [
    "!pip install pipreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pipreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1abbe3dec11a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# import nest_asyncio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#from utils.pipeline import *\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreparation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# from typing import Any, Dict,List,Enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# First, we will need to import the library and initialize the main application object:\n",
    "import os\n",
    "import joblib\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, Request, File, UploadFile, HTTPException\n",
    "from pydantic import BaseModel\n",
    "# import nest_asyncio\n",
    "#from utils.pipeline import *\n",
    "#from utils.preparation import *\n",
    "\n",
    "# from typing import Any, Dict,List,Enum\n",
    "# import numpy as np  \n",
    "\n",
    "\"\"\"\n",
    "1. Set up the FastAPI application\n",
    "2. Load the model(s) into the application\n",
    "3. Create required API endpoint(s) for users to submit data:\n",
    "   - These could be CSV file(s), image(s), JSON object(s), etc.\n",
    "   - Handle incoming data appropriately\n",
    "4. Use the indended model to predict the result(s) on the data submitted\n",
    "5. If successful, return the predictions, else raise an error  \n",
    "\n",
    " \"\"\"\n",
    "\n",
    "## API INSTANTIATION\n",
    "## ----------------------------------------------------------------\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"Spam Detection API\",\n",
    "    description=\"A simple API that use Ml model to predict Spam \",\n",
    "    version=\"0.1\",\n",
    ")\n",
    "\n",
    "# Preprocess Heleper \n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text) # Effectively removes HTML markup tags\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    return text\n",
    "# Predict Function \n",
    "def classify_message(model, message):\n",
    "\n",
    "\tmessage = preprocessor(message)\n",
    "\tlabel = model.predict([message])[0]\n",
    "\tspam_prob = model.predict_proba([message])\n",
    "\n",
    "\treturn {'label': label, 'spam_probability': spam_prob[0][1]}\n",
    "\n",
    "# Creating the data model for data validation\n",
    "class ClientData(BaseModel):\n",
    "    message: str\n",
    "\n",
    "# Load  the model  a serialized .joblib file\n",
    "#joblib_filename = \"models/pipeline_model_lgbm_final.joblib\"\n",
    "#model = joblib.load(joblib_filename)\n",
    "with open('models/spam_classifier.joblib', 'rb') as joblib_filename:\n",
    "    model = joblib.load(joblib_filename)\n",
    "   \n",
    "\n",
    "## API ENDPOINTS\n",
    "## ----------------------------------------------------------------\n",
    "\n",
    "##################\n",
    "@app.get('/')\n",
    "def index():\n",
    "    \"\"\"\n",
    "  This is a first docstring.\n",
    "  \"\"\"\n",
    "    return {'message': 'This is a Fraud  Classification API!'}\n",
    "\n",
    "\n",
    "# Tester\n",
    "@app.get('/ping')\n",
    "def ping():\n",
    "    '''\n",
    "  This is a first docstring.\n",
    "  '''\n",
    "    return ('pong', 200)\n",
    "\n",
    "\n",
    "# Defining the prediction endpoint without data validation\n",
    "@app.post('/basic_predict_spam')\n",
    "async def basic_predict(request: Request):\n",
    "    '''\n",
    "    This is a first docstring.\n",
    "    '''\n",
    "    # Getting the JSON from the body of the request\n",
    "    messsage = await request.json()\n",
    "    return classify_message(model, message)\n",
    "\n",
    "\n",
    "# We now define the function that will be executed for each URL request and return the value:\n",
    "@app.post(\"/predict-spam\")\n",
    "async  def predict_fraud(item :ClientData):\n",
    "    \"\"\"\n",
    "    A simple function that receive a client data and predict Spam.\n",
    "    :param client_data:\n",
    "    :return: prediction, probabilities\n",
    "    \"\"\"\n",
    "    # perform prediction\n",
    "    #df =pd.DataFrame([item])\n",
    "    #h=item.dict()\n",
    "    return classify_message(model, str(item))\n",
    "\t\n",
    "# Create the POST endpoint with path '/predict_csv'\n",
    "@app.post(\"/predict_csv\")\n",
    "async def create_upload_file(file: UploadFile = File(...)):\n",
    "    # Handle the file only if it is a CSV\n",
    "    if file.filename.endswith(\".csv\"):\n",
    "        # Create a temporary file with the same name as the uploaded \n",
    "        # CSV file to load the data into a pandas Dataframe\n",
    "        with open(file.filename, \"wb\")as f:\n",
    "            f.write(file.file.read())\n",
    "        data = pd.read_csv(file.filename)\n",
    "        os.remove(file.filename)\n",
    "        # Return a JSON object containing the model predictions\n",
    "        return {\n",
    "            \"predections\": model.predict(data)\n",
    "        }    \n",
    "    else:\n",
    "        # Raise a HTTP 400 Exception, indicating Bad Request \n",
    "        # (you can learn more about HTTP response status codes here)\n",
    "        raise HTTPException(status_code=400, detail=\"Invalid file format. Only CSV Files accepted.\")\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=4000)\n",
    "# uvicorn app:app --reload"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
