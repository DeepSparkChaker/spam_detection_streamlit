{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import re # regex library\n",
    "# Read the Data\n",
    "# Train, Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Training a Neural Network Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.8\n"
     ]
    }
   ],
   "source": [
    "!python --version "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Model config in json format\"\"\"\n",
    "cfg = {\n",
    "    \"data\": {\n",
    "        ##alldata\n",
    "        \"path\": \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/Deploy_Spam_Detection/data/spam_data.csv\"\n",
    "        # small sample:\n",
    "       # \"path\": \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/FraudDetection/X_train_transactions_train.csv\"\n",
    "    },\n",
    "    # \"data_test\": {\n",
    "    #   \"path\": \"../input/ventilator-pressure-prediction/test.csv\"\n",
    "    # },\n",
    "    # \"data_submission\": {\n",
    "    #   \"path\": \"../input/ventilator-pressure-prediction/test.csv\"\n",
    "    # },\n",
    "    \"train\": {\n",
    "        'fit_params': {'early_stopping_rounds': 100, 'verbose': 55000},\n",
    "        'n_fold': 5,\n",
    "        'seeds': [2021],\n",
    "        'target_col': \"Fraud\",\n",
    "        'debug': False\n",
    "\n",
    "    },\n",
    "    \"model\": {'n_estimators': 11932, \n",
    "                    'max_depth': 16, \n",
    "                    'learning_rate': 0.005352340588475586,\n",
    "                    'lambda_l1': 1.4243404105489683e-06,\n",
    "                    'lambda_l2': 0.04777178032735788,\n",
    "                    'num_leaves': 141, \n",
    "                    'feature_fraction': 0.6657626611307914, \n",
    "                    'bagging_fraction': 0.9115997498937961,\n",
    "                    'bagging_freq': 1,\n",
    "                    'min_child_samples': 51,\n",
    "                     \"objective\": \"binary\",\n",
    "                     #\"metric\": \"binary_logloss\",\n",
    "                     \"verbosity\": -1,\n",
    "                     \"boosting_type\": \"gbdt\",\n",
    "                     #\"random_state\": 228,\n",
    "                     \"metric\": \"auc\",\n",
    "                     #\"device\": \"gpu\",\n",
    "                     'tree_method': \"gpu_hist\"\n",
    "                    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    \"\"\"save log\"\"\"\n",
    "    def __init__(self, path):\n",
    "        self.general_logger = logging.getLogger(path)\n",
    "        stream_handler = logging.StreamHandler()\n",
    "        file_general_handler = logging.FileHandler(os.path.join(path, 'Experiment.log'))\n",
    "        if len(self.general_logger.handlers) == 0:\n",
    "            self.general_logger.addHandler(stream_handler)\n",
    "            self.general_logger.addHandler(file_general_handler)\n",
    "            self.general_logger.setLevel(logging.INFO)\n",
    "\n",
    "    def info(self, message):\n",
    "        # display time\n",
    "        self.general_logger.info('[{}] - {}'.format(self.now_string(), message))\n",
    "\n",
    "    @staticmethod\n",
    "    def now_string():\n",
    "        return str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    \n",
    "class Util:\n",
    "    \"\"\"save & load\"\"\"\n",
    "    @classmethod\n",
    "    def dump(cls, value, path):\n",
    "        joblib.dump(value, path, compress=True)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        return joblib.load(path)\n",
    "        \n",
    "class HorizontalDisplay:\n",
    "    \"\"\"display dataframe\"\"\"\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        template = '<div style=\"float: left; padding: 10px;\">{0}</div>'\n",
    "        return \"\\n\".join(template.format(arg._repr_html_())\n",
    "                         for arg in self.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Config class\"\"\"\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "class Config:\n",
    "    name_v1 = \"lgb baseline\"\n",
    "    \"\"\"Config class which contains data, train and model hyperparameters\"\"\"\n",
    "    def __init__(self, data, train, model):\n",
    "        self.data = data\n",
    "        self.train = train\n",
    "        self.model = model\n",
    "    @classmethod\n",
    "    def from_json(cls, cfg):\n",
    "        \"\"\"Creates config from json\"\"\"\n",
    "        params = json.loads(json.dumps(cfg), object_hook=lambda d: SimpleNamespace(**d))\n",
    "        return cls(params.data, params.train, params.model)\n",
    "\n",
    "class HelperObject(object):\n",
    "    \"\"\"Helper class to convert json into Python object\"\"\"\n",
    "    def __init__(self, dict_):\n",
    "        self.__dict__.update(dict_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "  Category                                            Message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "shape of data (5572, 2)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Data Loader\"\"\"\n",
    "class DataLoader:\n",
    "    \"\"\"Data Loader class\"\"\"\n",
    "    @staticmethod\n",
    "    def load_data(data_config):\n",
    "        \"\"\"Loads dataset from path\"\"\"\n",
    "        return pd.read_csv(data_config.path)\n",
    "    \n",
    "%time\n",
    "if __name__ == \"__main__\":\n",
    "    train = DataLoader().load_data(Config.from_json(cfg).data)\n",
    "    print(train.head())\n",
    "    print('shape of data {}'.format(train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\rzouga\\\\Desktop\\\\ALLINHERE\\\\ALLINHERE\\\\Deploy_Spam_Detection\\\\notebook'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "current_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloder=DataLoader()\n",
    "data = dataloder.load_data(Config.from_json(cfg).data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('./data/spam_data.csv')\n",
    "# Text Preprocessing\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text) # Effectively removes HTML markup tags\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    return text\n",
    "# Define X and y \n",
    "X = data['Message'].apply(preprocessor)\n",
    "y = data['Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'squeeeeeze this is christmas hug if u lik my frndshp den hug me back if u get 3 u r cute 6 u r luvd 9 u r so lucky none people hate u :) ;)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99      1448\n",
      "        spam       0.96      0.92      0.94       224\n",
      "\n",
      "    accuracy                           0.98      1672\n",
      "   macro avg       0.97      0.96      0.96      1672\n",
      "weighted avg       0.98      0.98      0.98      1672\n",
      "\n",
      "Accuracy: 98.38516746411483 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/Deploy_Spam_Detection/models/spam_classifier.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, \n",
    "                        max_features=700, \n",
    "                        ngram_range=(1,1))\n",
    "neural_net_pipeline = Pipeline([('vectorizer', tfidf), \n",
    "                                ('nn', MLPClassifier(hidden_layer_sizes=(700, 700)))])\n",
    "neural_net_pipeline.fit(X_train, y_train)\n",
    "# Testing the Pipeline\n",
    "y_pred = neural_net_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Accuracy: {} %'.format(100 * accuracy_score(y_test, y_pred)))\n",
    "# Saving the Pipeline\n",
    "dump(neural_net_pipeline, 'C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/Deploy_Spam_Detection/models/spam_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21986705334812853"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model data\n",
    "import joblib\n",
    "#f = \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/FraudDetection/DeployPipeComplet/models/model_test.joblib\"\n",
    "f = \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/Deploy_Spam_Detection/models/spam_classifier.joblib\"\n",
    "model = joblib.load(f)\n",
    "item={}\n",
    "item={\"message\":'squeeeeeze this is christmas hug if u lik my frndshp den hug me back if u get 3 u r cute 6 u r luvd 9 u r so lucky none people hate u :) ;)'\n",
    "     }\n",
    "df = pd.json_normalize(item)\n",
    "df2 =pd.DataFrame([item])\n",
    "prediction = model.predict_proba(df2)\n",
    "prediction[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>squeeeeeze this is christmas hug if u lik my f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message\n",
       "0  squeeeeeze this is christmas hug if u lik my f..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(df)\n",
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'proba': 0.21986705334812853, 'result': 'ham'}\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_proba(df)\n",
    "prediction_final=model.predict(df)\n",
    "h={\"proba\": prediction[0][1], \"result\" :prediction_final[0]}\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [3348]\n",
      "Started server process [3348]\n",
      "INFO:     Waiting for application startup.\n",
      "Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:4000 (Press CTRL+C to quit)\n",
      "Uvicorn running on http://127.0.0.1:4000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:60338 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60343 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60343 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60359 - \"POST /predict-spam HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:60414 - \"POST /predict-spam HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "# First, we will need to import the library and initialize the main application object:\n",
    "import joblib\n",
    "import uvicorn\n",
    "from fastapi import FastAPI,Request, File, UploadFile, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import nest_asyncio\n",
    "from typing import Any, Dict,List\n",
    "        \n",
    "## API INSTANTIATION\n",
    "## ----------------------------------------------------------------\n",
    "       \n",
    "app = FastAPI(\n",
    "    title=\"Spam Detection API\",\n",
    "    description=\"A simple API that use Ml model to predict Spam \",\n",
    "    version=\"0.1\",\n",
    ")\n",
    "# Creating the data model for data validation\n",
    "class ClientData(BaseModel):\n",
    "    message: str\n",
    "#load model data\n",
    "f = \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/Deploy_Spam_Detection/models/spam_classifier.joblib\"\n",
    "#f = \"C:/Users/rzouga/Desktop/ALLINHERE/ALLINHERE/FraudDetection/DeployPipeComplet/models/pipeline_model_lgbm_final.joblib\"\n",
    "model = joblib.load(f)\n",
    "    \n",
    "## API ENDPOINTS\n",
    "## ----------------------------------------------------------------\n",
    "## API ENDPOINTS\n",
    "## ----------------------------------------------------------------\n",
    "\n",
    "# Preprocess Heleper \n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text) # Effectively removes HTML markup tags\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    return text\n",
    "# Predict Function \n",
    "def classify_message(model, message):\n",
    "\n",
    "\tmessage = preprocessor(message)\n",
    "\tlabel = model.predict([message])[0]\n",
    "\tspam_prob = model.predict_proba([message])\n",
    "\n",
    "\treturn {'label': label, 'spam_probability': spam_prob[0][1]}\n",
    "\n",
    "##################\n",
    "@app.get('/')\n",
    "def index():\n",
    "  '''\n",
    "  This is a first docstring.\n",
    "  '''\n",
    "  return {'message': 'This is a Fraud  Classification API!'}\n",
    "\n",
    "# Tester\n",
    "@app.get('/ping')\n",
    "def ping():\n",
    "  '''\n",
    "  This is a first docstring.\n",
    "  '''\n",
    "  return ('pong', 200)\n",
    "# Defining the prediction endpoint without data validation\n",
    "@app.post('/basic_predict_spam')\n",
    "async def basic_predict(request: Request):\n",
    "    '''\n",
    "    This is a first docstring.\n",
    "    '''\n",
    "    # Getting the JSON from the body of the request\n",
    "    messsage = await request.json()\n",
    "    return classify_message(model, message)\n",
    "\n",
    "# We now define the function that will be executed for each URL request and return the value:\n",
    "@app.post(\"/predict-spam\")\n",
    "async  def predict_fraud(item :ClientData):\n",
    "    \"\"\"\n",
    "    A simple function that receive a client data and predict Spam.\n",
    "    :param client_data:\n",
    "    :return: prediction, probabilities\n",
    "    \"\"\"\n",
    "    # perform prediction\n",
    "    #df =pd.DataFrame([item])\n",
    "    #h=item.dict()\n",
    "    return classify_message(model, str(item))\n",
    "    \n",
    "    # Create the POST endpoint with path '/predict'\n",
    "@app.post(\"/predict_csv\")\n",
    "async def create_upload_file(file: UploadFile = File(...)):\n",
    "    # Handle the file only if it is a CSV\n",
    "    if file.filename.endswith(\".csv\"):\n",
    "        # Create a temporary file with the same name as the uploaded \n",
    "        # CSV file to load the data into a pandas Dataframe\n",
    "        with open(file.filename, \"wb\")as f:\n",
    "            f.write(file.file.read())\n",
    "        data = pd.read_csv(file.filename)\n",
    "        os.remove(file.filename)\n",
    "        # Return a JSON object containing the model predictions\n",
    "        return {\n",
    "            \"predictions\": model.predict(data)\n",
    "        }    \n",
    "    else:\n",
    "        # Raise a HTTP 400 Exception, indicating Bad Request \n",
    "        # (you can learn more about HTTP response status codes here)\n",
    "        raise HTTPException(status_code=400, detail=\"Invalid file format. Only CSV Files accepted.\")\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=4000)\n",
    "# uvicorn app:app --reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
